# local-SLM-library

ãƒ­ãƒ¼ã‚«ãƒ«ç’°å¢ƒã§ RAGï¼ˆRetrieval-Augmented Generationï¼‰ã‚’å®Ÿè£…ãƒ»æ¤œè¨¼ã™ã‚‹ãŸã‚ã® Python ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã§ã™ã€‚LangChain + Ollama ã‚’åŸºç›¤ã¨ã—ã€ã‚«ãƒ†ã‚´ãƒªãƒ™ãƒ¼ã‚¹ã®ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ç®¡ç†ã¨æŸ”è»Ÿãªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆè¨­è¨ˆãŒç‰¹å¾´ã§ã™ã€‚

## ğŸ“¦ ä¸»ãªæ©Ÿèƒ½

- Markdown / PDF / Word / PPTX ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ™ã‚¯ãƒˆãƒ«åŒ–ã—ã€ã‚«ãƒ†ã‚´ãƒªåˆ¥ã«ç®¡ç†
- è¤‡æ•°ã®ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ã‚’ãƒãƒ¼ã‚¸ã—ã¦çµ±åˆæ¤œç´¢
- LangChain 0.3 ç³»ã«å¯¾å¿œã—ãŸ Conversational Retrieval QA æ§‹ç¯‰
- æ—¥æœ¬èªãƒ»å¤šè¨€èªå¯¾å¿œï¼ˆGranite 3.2:8b ã§ç¢ºèªæ¸ˆã¿ï¼‰
- PromptTemplate ã«ã‚ˆã‚‹æŸ”è»Ÿãªå¯¾è©±è¨­è¨ˆ
- docling ã«ã‚ˆã‚‹é«˜åº¦ãªæ–‡æ›¸å¤‰æ›ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ï¼ˆMarkdown å¤‰æ›ï¼‰

## ğŸ§° ä½¿ç”¨æŠ€è¡“

- Python 3.11+
- [LangChain](https://python.langchain.com/)
- [Ollama](https://ollama.com/)
- [FAISS](https://github.com/facebookresearch/faiss)
- [docling](https://github.com/docling-ai/docling)
- Unstructured / PyMuPDF ãªã©

## ğŸ“ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹æˆ

```
modules/core/
â”œâ”€â”€ main.py            # å®Ÿè¡Œã‚¹ã‚¯ãƒªãƒ—ãƒˆ
â”œâ”€â”€ chain.py           # ãƒã‚§ãƒ¼ãƒ³æ§‹ç¯‰ã¨ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆè¨­è¨ˆ
â”œâ”€â”€ rag.py             # ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢å‡¦ç†ã¨çµ±åˆ
â”œâ”€â”€ construct.py       # åŸ‹ã‚è¾¼ã¿ç”Ÿæˆã¨Markdownå¤‰æ›
â”œâ”€â”€ prompts.py         # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆå®šç¾©
â””â”€â”€ sample/            # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ï¼ˆMarkdownãƒ»ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ï¼‰
```

## ğŸš€ ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—æ‰‹é †

### 1. ä¾å­˜ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«

```bash
pip install -r requirements.txt
```

ã¾ãŸã¯ã€å¿…è¦ã«å¿œã˜ã¦ä»¥ä¸‹ã‚’æ‰‹å‹•ã§ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ï¼š

```bash
pip install langchain langchain-community langchain-ollama pydantic faiss-cpu unstructured
```

### 2. Ollama ãƒ¢ãƒ‡ãƒ«ã®å–å¾—ï¼ˆä¾‹ï¼‰

```bash
ollama pull granite3.2:8b
ollama serve
```

### 3. å®Ÿè¡Œ

```bash
python modules/core/main.py
```

## ğŸ“š ä½¿ç”¨æ–¹æ³•ã®æ¦‚è¦

### 1. ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ã®æ§‹ç¯‰ï¼ˆconstruct.vectorizationï¼‰

```python
vectorization(
    in_file="path/to/file.pdf",
    md_path="path/to/output.md",
    vect_path="path/to/vectorstore",
    category="example"
)
```

### 2. QAãƒã‚§ãƒ¼ãƒ³ã®æº–å‚™ï¼ˆã‚«ãƒ†ã‚´ãƒªãƒ™ãƒ¼ã‚¹ï¼‰

```python
qa_chain = prepare_chain_for_category(
    llm=my_llm,
    category="example",
    base_path=Path("path/to/vectorhouse"),
    chain_type="conversational",
    prompt_template=CUSTOM_PROMPT
)
```

### 3. å¯¾è©±å®Ÿè¡Œ

```python
response = qa_chain.invoke({
    "input": "è³ªå•å†…å®¹",
    "chat_history": []
})
```

## ğŸ§  ã‚«ã‚¹ã‚¿ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆä¾‹

```python
from langchain.prompts import ChatPromptTemplate

CUSTOM_PROMPT = ChatPromptTemplate.from_template("""
ä»¥ä¸‹ã®æ–‡è„ˆã«åŸºã¥ã„ã¦ã€æ­£ç¢ºã‹ã¤è«–ç†çš„ãªæ—¥æœ¬èªã§å›ç­”ã—ã¦ãã ã•ã„ã€‚

æ–‡è„ˆ:
{context}

è³ªå•:
{input}
""")
```

## âš ï¸ æ³¨æ„ç‚¹

- Granite Embedding 278m ãƒ¢ãƒ‡ãƒ«ã¯ä¸€éƒ¨ç’°å¢ƒã§ã‚¯ãƒ©ãƒƒã‚·ãƒ¥ã®å ±å‘ŠãŒã‚ã‚Šã¾ã™ï¼ˆ`nomic-embed-text:latest` ã‚’æ¨å¥¨ï¼‰
- LangChain ã®ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã¯ `0.3.x` ã«å›ºå®šã—ã¦ã‚ã‚Šã¾ã™ï¼ˆä»¥é™ã®äº’æ›æ€§ã¯æœªæ¤œè¨¼ï¼‰
- Pydantic v2 ç³»ã«å¯¾å¿œ

## ğŸ“ ãƒ©ã‚¤ã‚»ãƒ³ã‚¹

MIT License

## ğŸ“¬ é–‹ç™ºè€…

Yu Fujimotoï½œTajima R&D
GitHub: [@tajima-rd](https://github.com/tajima-rd)
```

---

ã”å¸Œæœ›ã«å¿œã˜ã¦ã€è‹±èªç‰ˆã‚„å›³ä»˜ãã® README ã‚‚ç”¨æ„å¯èƒ½ã§ã™ã€‚å¿…è¦ã§ã™ã‹ï¼Ÿ
