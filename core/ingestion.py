# -----------------------------
# æ¨™æº–ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
# -----------------------------
import os
import json
from uuid import uuid4
from typing import List, Any, Optional, Dict
from pathlib import Path

# -----------------------------
# ã‚µãƒ¼ãƒ‰ãƒ‘ãƒ¼ãƒ†ã‚£ãƒ©ã‚¤ãƒ–ãƒ©ãƒª (LangChain)
# -----------------------------
from langchain_community.embeddings import OllamaEmbeddings # type: ignore
from langchain_community.vectorstores import FAISS # type: ignore
from langchain_core.documents import Document # type: ignore
from langchain_core.runnables import Runnable # type: ignore
from langchain_core.prompts import BasePromptTemplate # type: ignore # ãƒã‚§ãƒ¼ãƒ³æ§‹ç¯‰é–¢æ•°ã§å¿…è¦ã«ãªã‚‹å¯èƒ½æ€§


# -----------------------------
# è‡ªä½œãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
# -----------------------------
from . import document_utils as docutils
from . import retriever_utils # RetrieverCategory, load_vectorstore, create_faiss_retriever, merge_vectorstore ãªã©ãŒå¿…è¦
from .retriever_utils import RetrieverCategory, load_vectorstore, merge_vectorstore, create_faiss_retriever

try:
    from .chain_factory import get_chain # ç›¸å¯¾ã‚¤ãƒ³ãƒãƒ¼ãƒˆã«ä¿®æ­£
except ImportError:
    print("âš ï¸ chain_factory ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ prepare_chain_from_path é–¢æ•°ã¯ä½¿ç”¨ã§ãã¾ã›ã‚“ã€‚")
    get_chain = None # ã‚¤ãƒ³ãƒãƒ¼ãƒˆã§ããªã‹ã£ãŸå ´åˆã¯ None ã«è¨­å®š

def _save_documents_to_faiss(
    documents: List[Document],
    vect_path: str,
    embedding_name: str,
    category: retriever_utils.RetrieverCategory,
    loader_type: str, # loader_type ã¯ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã«ä¿å­˜ç”¨
) -> bool:
    """
    æ–‡æ›¸ãƒªã‚¹ãƒˆã‚’å—ã‘å–ã‚Šã€åˆ†å‰²ã€ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ä»˜ä¸ã€FAISSä¿å­˜ã‚’è¡Œã†ãƒ—ãƒ©ã‚¤ãƒ™ãƒ¼ãƒˆãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°ã€‚

    Parameters:
    - documents: ä¿å­˜å¯¾è±¡ã® LangChain Document ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®ãƒªã‚¹ãƒˆ
    - vect_path: ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ã‚’ä¿å­˜ã™ã‚‹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ãƒ‘ã‚¹
    - embedding_name: ä½¿ç”¨ã™ã‚‹åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«ã®åå‰ (Ollama ãƒ¢ãƒ‡ãƒ«åãªã©)
    - category: ã“ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãƒãƒƒãƒã«ç´ã¥ã‘ã‚‹ RetrieverCategory ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
    - loader_type: ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®å…ƒã¨ãªã£ãŸãƒ­ãƒ¼ãƒ€ãƒ¼ã®ã‚¿ã‚¤ãƒ—ã‚’ç¤ºã™æ–‡å­—åˆ— (ä¾‹: "markdown", "text")

    Returns:
    - bool: ä¿å­˜ã«æˆåŠŸã—ãŸã‹
    """
    # åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–
    try:
        embeddings = OllamaEmbeddings(model=embedding_name) # type: ignore
    except Exception as e:
        print(f"âŒ åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«ã®åˆæœŸåŒ–ã«å¤±æ•—ã—ã¾ã—ãŸ ({embedding_name}): {e}")
        return False

    print("ãƒ†ã‚­ã‚¹ãƒˆã‚’åˆ†å‰²ã—ã¦ãƒãƒ£ãƒ³ã‚¯ã‚’å‰²ã‚Šå½“ã¦ã¾ã™ã€‚")
    try:
        # ãƒ­ãƒ¼ãƒ‰å…ƒã® loader_type ã«åŸºã¥ã„ã¦é©åˆ‡ãªã‚¹ãƒ—ãƒªãƒƒã‚¿ãƒ¼ã‚’æ¨å¥¨
        splitter = docutils.suggest_text_splitter(
            documents=documents,
            loader_type=loader_type
        )
        split_docs = splitter.split_documents(documents)
    except Exception as e:
        print(f"âŒ ãƒ†ã‚­ã‚¹ãƒˆåˆ†å‰²ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return False


    # å„ãƒãƒ£ãƒ³ã‚¯ã«ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ï¼ˆdoc_id, categoryãªã©ï¼‰ã‚’ä»˜ä¸
    for doc in split_docs:
        # æ—¢å­˜ã® doc_id ãŒã‚ã‚‹å ´åˆã‚‚ã‚ã‚‹ãŒã€å†æ§‹ç¯‰æ™‚ã¯æ–°ã—ã„ UUID ã‚’å‰²ã‚Šå½“ã¦ã‚‹ã®ãŒå®‰å…¨
        doc.metadata["doc_id"] = str(uuid4())

        # category ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®æ›´æ–°/è¿½åŠ  (æ—¢å­˜ãŒã‚ã‚Œã°ãƒãƒ¼ã‚¸)
        # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆè‡ªèº«ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã« category æƒ…å ±ã‚’æŒãŸã›ã‚‹
        existing_category = doc.metadata.get("category", {})
        if not isinstance(existing_category, dict):
             existing_category = {} # æ—¢å­˜ãŒdictã§ãªã„å ´åˆã¯åˆæœŸåŒ–

        # category ã‚’è¾æ›¸ã«å¤‰æ›ã—ã¦ãƒãƒ¼ã‚¸
        # æ–°ã—ã„ã‚«ãƒ†ã‚´ãƒªã«å«ã¾ã‚Œã‚‹ã‚­ãƒ¼ãŒæ—¢å­˜ã‚«ãƒ†ã‚´ãƒªã«ã‚ã‚Œã°ä¸Šæ›¸ãã•ã‚Œã¾ã™
        doc.metadata["category"] = {**existing_category, **category.to_dict()}

    # ãƒãƒ£ãƒ³ã‚¯ãŒãªã„å ´åˆã¯ä¿å­˜ã—ãªã„
    if not split_docs:
         print("âš ï¸ åˆ†å‰²ã•ã‚ŒãŸãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆãŒã‚ã‚Šã¾ã›ã‚“ã€‚ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ã¯ä¿å­˜ã•ã‚Œã¾ã›ã‚“ã€‚")
         return False

    # FAISSä¿å­˜
    print(f"âœ¨ {len(split_docs)} ä»¶ã®ãƒãƒ£ãƒ³ã‚¯ã‚’ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ã«ä¿å­˜ã—ã¾ã™ã€‚")
    if split_docs:
         # æœ€åˆã®ãƒãƒ£ãƒ³ã‚¯ã®å†…å®¹ã¨ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ‡ãƒãƒƒã‚°è¡¨ç¤º
         print(f"[DEBUG] æœ€åˆã®ãƒãƒ£ãƒ³ã‚¯ (ä¸€éƒ¨): {split_docs[0].page_content[:200]}...")
         print(f"[DEBUG] æœ€åˆã®ãƒãƒ£ãƒ³ã‚¯ ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿: {split_docs[0].metadata}")

    try:
        vectorstore = FAISS.from_documents(split_docs, embeddings) # type: ignore

        # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã—ãªã„å ´åˆãŒã‚ã‚‹ã®ã§ä½œæˆ
        Path(vect_path).mkdir(parents=True, exist_ok=True)
        vectorstore.save_local(vect_path)

    except Exception as e:
        print(f"âŒ FAISS ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ã®ä¿å­˜ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        return False


    # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®ä¿å­˜ (ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå…¨ä½“ã«é–¢ã™ã‚‹æƒ…å ±)
    metadata = {
        "embedding_model": embedding_name, # ãƒ¢ãƒ‡ãƒ«åè‡ªä½“ã‚’ä¿å­˜
        "loader_type": loader_type,
        "category": category.to_dict(), # ã“ã®ä¿å­˜ãƒãƒƒãƒå…¨ä½“ã®ä»£è¡¨ã‚«ãƒ†ã‚´ãƒªã¨ã—ã¦è¨˜éŒ²
        # ãã®ä»–ã€ã‚¹ãƒ—ãƒªãƒƒã‚¿ãƒ¼è¨­å®šãªã©ã‚’è¿½åŠ ã™ã‚‹ã®ã‚‚è‰¯ã„ã‹ã‚‚ã—ã‚Œãªã„
    }
    metadata_file_path = os.path.join(vect_path, "metadata.json")
    try:
        with open(metadata_file_path, "w", encoding="utf-8") as f:
            json.dump(metadata, f, indent=2, ensure_ascii=False)
    except Exception as e:
        print(f"âš ï¸ ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ« ({metadata_file_path}) ã®ä¿å­˜ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        # ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢è‡ªä½“ã¯ä¿å­˜ã§ãã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ã®ã§ True ã‚’è¿”ã™ã“ã¨ã‚‚æ¤œè¨
        # ã“ã“ã§ã¯ä¸€è²«æ€§ã®ãŸã‚ False ã¨ã—ã¾ã™ãŒã€è¨­è¨ˆã«ã‚ˆã‚‹

    print(f"âœ… ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ã¨ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {vect_path}")
    return True

def save_markdown_to_vectorstore(
    md_path: str,
    vect_path: str,
    embedding_name: str,
    category: RetrieverCategory,
    loader_type: str = "markdown",
) -> bool:
    """
    Markdownãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ãƒ­ãƒ¼ãƒ‰ã€åˆ†å‰²ã—ã€FAISSãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ã¨ã—ã¦ä¿å­˜ã™ã‚‹ã€‚

    Parameters:
    - md_path: å…¥åŠ›Markdownãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
    - vect_path: ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ã‚’ä¿å­˜ã™ã‚‹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ãƒ‘ã‚¹
    - embedding_name: ä½¿ç”¨ã™ã‚‹åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«å
    - category: ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã«ç´ã¥ã‘ã‚‹ RetrieverCategory ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
    - loader_type: ä½¿ç”¨ã™ã‚‹ãƒ­ãƒ¼ãƒ€ãƒ¼ã‚¿ã‚¤ãƒ— (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: "markdown")

    Returns:
    - bool: ä¿å­˜ã«æˆåŠŸã—ãŸã‹
    """
    if not os.path.exists(md_path):
        print(f"âŒ å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {md_path}")
        return False

    try:
        # ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã®ãƒ­ãƒ¼ãƒ‰
        documents = docutils.load_documents(md_path, loader_type)
        if not documents:
             print(f"âš ï¸ ãƒ•ã‚¡ã‚¤ãƒ« {md_path} ã‹ã‚‰ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ãƒ­ãƒ¼ãƒ‰ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
             return False

        # ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°ã‚’å‘¼ã³å‡ºã—ã¦ä¿å­˜
        return _save_documents_to_faiss(
            documents=documents,
            vect_path=vect_path,
            embedding_name=embedding_name,
            category=category,
            loader_type=loader_type
        )
    except Exception as e:
        print(f"âŒ Markdownã‹ã‚‰ã®ä¿å­˜å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return False

def save_text_to_vectorstore(
    text: str,
    vect_path: str,
    embedding_name: str,
    category: RetrieverCategory,
    loader_type: str = "text",
) -> bool:
    """
    ãƒ—ãƒ¬ãƒ¼ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæ–‡å­—åˆ—ã‹ã‚‰ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã‚’ç”Ÿæˆã—ã€åˆ†å‰²ã€FAISSãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ã¨ã—ã¦ä¿å­˜ã™ã‚‹ã€‚

    Parameters:
    - text: ä¿å­˜å¯¾è±¡ã®ãƒ—ãƒ¬ãƒ¼ãƒ³ãƒ†ã‚­ã‚¹ãƒˆæ–‡å­—åˆ—
    - vect_path: ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ã‚’ä¿å­˜ã™ã‚‹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ãƒ‘ã‚¹
    - embedding_name: ä½¿ç”¨ã™ã‚‹åŸ‹ã‚è¾¼ã¿ãƒ¢ãƒ‡ãƒ«å
    - category: ã“ã®ãƒ†ã‚­ã‚¹ãƒˆã«ç´ã¥ã‘ã‚‹ RetrieverCategory ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
    - loader_type: ä½¿ç”¨ã™ã‚‹ãƒ­ãƒ¼ãƒ€ãƒ¼ã‚¿ã‚¤ãƒ— (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: "text")

    Returns:
    - bool: ä¿å­˜ã«æˆåŠŸã—ãŸã‹
    """
    if not text:
        print("âš ï¸ ä¿å­˜å¯¾è±¡ã®ãƒ†ã‚­ã‚¹ãƒˆãŒç©ºã§ã™ã€‚")
        return False

    try:
        # Documentã«å¤‰æ›ï¼ˆmetadataã¯ã‚ã¨ã§ä»˜ä¸ï¼‰
        document = Document(page_content=text, metadata={})
        documents = [document]

        # ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°ã‚’å‘¼ã³å‡ºã—ã¦ä¿å­˜
        return _save_documents_to_faiss(
            documents=documents,
            vect_path=vect_path,
            embedding_name=embedding_name,
            category=category,
            loader_type=loader_type
        )
    except Exception as e:
        print(f"âŒ ãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ã®ä¿å­˜å‡¦ç†ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return False

def prepare_chain_from_path(
    llm: Any,
    faiss_paths: list[Path],
    chain_type: str = "conversational",
    k: int = 5,
    prompt_template: Optional[BasePromptTemplate] = None,
    **kwargs: Any # get_chain ã«æ¸¡ã™è¿½åŠ å¼•æ•°
) -> Optional[Runnable]:
    """
    æŒ‡å®šãƒ‘ã‚¹é…ä¸‹ã® FAISS ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ã‚’çµ±åˆã—ã€Retriever ãŠã‚ˆã³ RAG ãƒã‚§ãƒ¼ãƒ³ã‚’æ§‹ç¯‰ã™ã‚‹ã€‚
    (Ingestion + Chain Factory ã®çµ„ã¿åˆã‚ã›æ©Ÿèƒ½)

    Parameters:
    - llm: è¨€èªãƒ¢ãƒ‡ãƒ«
    - faiss_paths: ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ (.faiss ãŠã‚ˆã³ index.faiss ã‚’å«ã‚€ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª) ã®ãƒ‘ã‚¹ã®ãƒªã‚¹ãƒˆ
    - chain_type: ãƒã‚§ãƒ¼ãƒ³ã®ç¨®é¡ ("conversational", "retrievalqa" ãªã©)
    - k: æ¤œç´¢æ•°ï¼ˆRetrieverç”¨ï¼‰
    - prompt_template: combine_documents ç”¨ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆä»»æ„ï¼‰
    - kwargs: get_chain ã«æ¸¡ã™ãã®ä»–ã®ã‚ªãƒ—ã‚·ãƒ§ãƒ³

    Returns:
    - LangChain ãƒã‚§ãƒ¼ãƒ³ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ (Runnable)ï¼ˆæˆåŠŸæ™‚ï¼‰ã€ã¾ãŸã¯ Noneï¼ˆå¤±æ•—æ™‚ï¼‰

    Raises:
    - FileNotFoundError: ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ãƒ‘ã‚¹ãƒªã‚¹ãƒˆãŒç©ºã®å ´åˆã€ã¾ãŸã¯ãƒ‘ã‚¹ãŒå­˜åœ¨ã—ãªã„å ´åˆã€‚
    - ValueError: ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ã®çµ±åˆã«å•é¡ŒãŒã‚ã‚‹å ´åˆ (ä¾‹: ãƒ¢ãƒ‡ãƒ«ä¸ä¸€è‡´)ã€‚
    - Exception: ãƒã‚§ãƒ¼ãƒ³æ§‹ç¯‰ä¸­ã®ã‚¨ãƒ©ãƒ¼ã€‚
    """
    if get_chain is None:
        print("âŒ chain_factory ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãŒãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ãªã„ãŸã‚ã€prepare_chain_from_path ã¯å®Ÿè¡Œã§ãã¾ã›ã‚“ã€‚")
        return None

    if not faiss_paths:
        raise FileNotFoundError("ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ï¼ˆ.faiss ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼‰ã®ãƒ‘ã‚¹ãŒæŒ‡å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")

    print(f"ğŸ” {len(faiss_paths)} ä»¶ã®ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ã‚’çµ±åˆã—ã¾ã™ã€‚")

    # ãƒ‘ã‚¹ãŒå®Ÿéš›ã«å­˜åœ¨ã™ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
    existing_paths = [p for p in faiss_paths if p.exists() and p.is_dir()]
    if len(existing_paths) != len(faiss_paths):
         missing_paths = set(faiss_paths) - set(existing_paths)
         print(f"âš ï¸ æŒ‡å®šã•ã‚ŒãŸãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ãƒ‘ã‚¹ã®ä¸€éƒ¨ã¾ãŸã¯å…¨ã¦ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {[str(p) for p in missing_paths]}")
         # è¦‹ã¤ã‹ã£ãŸã‚‚ã®ã ã‘ã§ã‚‚å‡¦ç†ã‚’è©¦ã¿ã‚‹ã‹ã€ã‚¨ãƒ©ãƒ¼ã¨ã™ã‚‹ã‹
         # ã“ã“ã§ã¯ã‚¨ãƒ©ãƒ¼ã¨ã—ã¾ã™
         raise FileNotFoundError(f"æŒ‡å®šã•ã‚ŒãŸãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ãƒ‘ã‚¹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {[str(p) for p in missing_paths]}")

    try:
        # ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ã‚’çµ±åˆã—ã¦ Retriever ã‚’ä½œæˆ (retriever_utils ã®æ©Ÿèƒ½ã‚’ä½¿ç”¨)
        vectorstore = merge_vectorstore([str(p) for p in existing_paths])
        # é–¢æ•°åå¤‰æ›´: create_retriever -> create_faiss_retriever
        retriever = create_faiss_retriever(vectorstore, k=k)
    except Exception as e:
         print(f"âŒ ãƒ™ã‚¯ãƒˆãƒ«ã‚¹ãƒˆã‚¢ã®çµ±åˆã¾ãŸã¯Retrieverã®ä½œæˆã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
         return None

    # çµ±åˆã•ã‚ŒãŸRetrieverã‚’ä½¿ã£ã¦ãƒã‚§ãƒ¼ãƒ³ã‚’ä½œæˆ (chain_factory ã®æ©Ÿèƒ½ã‚’ä½¿ç”¨)
    try:
        chain = get_chain(
            llm=llm,
            chain_type=chain_type,
            retriever=retriever,
            prompt_template=prompt_template,
            k=k, # k ã¯ get_chain ã«æ¸¡ã™ (ä¼šè©±å±¥æ­´ã‚ã‚Šã®å ´åˆã® retriever ã«ã‚‚å½±éŸ¿)
            **kwargs, # ãã®ä»–ã®å¼•æ•°ã‚‚æ¸¡ã™
        )
        print(f"âœ… {chain_type} ãƒã‚§ãƒ¼ãƒ³ã‚’æ§‹ç¯‰ã—ã¾ã—ãŸã€‚")
        return chain
    except Exception as e:
        print(f"âŒ ãƒã‚§ãƒ¼ãƒ³æ§‹ç¯‰ã«å¤±æ•—ã—ã¾ã—ãŸ ({chain_type}): {e}")
        # traceback.print_exc() # å‘¼ã³å‡ºã—å…ƒã§å‡ºåŠ›ã•ã‚Œã‚‹ã¹ã
        return None